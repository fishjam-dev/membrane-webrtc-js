import {
  deserializeMediaEvent,
  generateCustomEvent,
  generateMediaEvent,
  MediaEvent,
  SerializedMediaEvent,
  serializeMediaEvent,
} from "./mediaEvent";
import { v4 as uuidv4 } from "uuid";
import EventEmitter from "events";
import TypedEmitter from "typed-emitter";
import { defaultBitrates, defaultSimulcastBitrates, simulcastTransceiverConfig } from "./const";
import { AddTrackCommand, Command, RemoveTrackCommand, ReplaceTackCommand } from "./commands";
import { Deferred } from "./deferred";

/**
 * Interface describing Endpoint.
 */
export interface Endpoint {
  /**
   * Endpoint's id. It is assigned by user in custom logic that use backend API.
   */
  id: string;
  /**
   * Type of the endpoint, e.g. "webrtc", "hls" or "rtsp".
   */
  type: string;
  /**
   * Any information that was provided in {@link WebRTCEndpoint.connect}.
   */
  metadata: any;
  /**
   * List of tracks that are sent by the endpoint.
   */
  tracks: Map<string, TrackContextImpl>;
}

/**
 * Type describing Voice Activity Detection statuses.
 *
 * - `speech` - voice activity has been detected
 * - `silence` - lack of voice activity has been detected
 */
export type VadStatus = "speech" | "silence";

const vadStatuses = ["speech", "silence"] as const;

/**
 * Type describing maximal bandwidth that can be used, in kbps. 0 is interpreted as unlimited bandwidth.
 */
export type BandwidthLimit = number;

/**
 * Type describing bandwidth limit for simulcast track.
 * It is a mapping (encoding => BandwidthLimit).
 * If encoding isn't present in this mapping, it will be assumed that this particular encoding shouldn't have any bandwidth limit
 */
export type SimulcastBandwidthLimit = Map<TrackEncoding, BandwidthLimit>;

/**
 * Type describing bandwidth limitation of a Track, including simulcast and non-simulcast tracks.
 * A sum type of `BandwidthLimit` and `SimulcastBandwidthLimit`
 */
export type TrackBandwidthLimit = BandwidthLimit | SimulcastBandwidthLimit;

/**
 * Type describing possible reasons for currently selected encoding.
 * - `other` - the exact reason couldn't be determined
 * - `encodingInactive` - previously selected encoding became inactive
 * - `lowBandwidth` - there is no longer enough bandwidth to maintain previously selected encoding
 */
export type EncodingReason = "other" | "encodingInactive" | "lowBandwidth";

/**
 * Simulcast configuration passed to {@link WebRTCEndpoint.addTrack}.
 *
 * At the moment, simulcast track is initialized in three versions - low, medium and high.
 * High resolution is the original track resolution, while medium and low resolutions
 * are the original track resolution scaled down by 2 and 4 respectively.
 */
export interface SimulcastConfig {
  /**
   * Whether to simulcast track or not.
   */
  enabled: boolean;
  /**
   * List of initially active encodings.
   *
   * Encoding that is not present in this list might still be
   * enabled using {@link WebRTCEndpoint.enableTrackEncoding}.
   */
  activeEncodings: TrackEncoding[];
}

/**
 * Track's context i.e. all data that can be useful when operating on track.
 */
interface TrackContextFields {
  readonly track: MediaStreamTrack | null;

  /**
   * Stream this track belongs to.
   */
  readonly stream: MediaStream | null;

  /**
   * Endpoint this track comes from.
   */
  readonly endpoint: Endpoint;

  /**
   * Track id. It is generated by RTC engine and takes form `endpoint_id:<random_uuidv4>`.
   * It is WebRTC agnostic i.e. it does not contain `mid` or `stream id`.
   */

  readonly trackId: string;
  /**
   * Simulcast configuration.
   * Only present for local tracks.
   */
  readonly simulcastConfig?: SimulcastConfig;

  /**
   * Any info that was passed in {@link WebRTCEndpoint.addTrack}.
   */
  readonly metadata: any;

  readonly maxBandwidth?: TrackBandwidthLimit;

  readonly vadStatus: VadStatus;

  /**
   * Encoding that is currently received.
   * Only present for remote tracks.
   */
  readonly encoding?: TrackEncoding;

  /**
   * The reason of currently selected encoding.
   * Only present for remote tracks.
   */
  readonly encodingReason?: EncodingReason;
}

export interface TrackContextEvents {
  /**
   * Emitted each time track encoding has changed.
   *
   * Track encoding can change in the following cases:
   * - when user requested a change
   * - when sender stopped sending some encoding (because of bandwidth change)
   * - when receiver doesn't have enough bandwidth
   *
   * Some of those reasons are indicated in {@link TrackContext.encodingReason}.
   */
  encodingChanged: (context: TrackContext) => void;

  /**
   * Emitted every time an update about voice activity is received from the server.
   */
  voiceActivityChanged: (context: TrackContext) => void;
}

export interface TrackContext extends TrackContextFields, TypedEmitter<Required<TrackContextEvents>> {}

type TrackNegotiationStatus = "awaiting" | "offered" | "done";

class TrackContextImpl
  extends (EventEmitter as new () => TypedEmitter<Required<TrackContextEvents>>)
  implements TrackContext
{
  endpoint: Endpoint;
  trackId: string;
  track: MediaStreamTrack | null = null;
  stream: MediaStream | null = null;
  metadata: any;
  simulcastConfig?: SimulcastConfig;
  maxBandwidth: TrackBandwidthLimit = 0;
  encoding?: TrackEncoding;
  encodingReason?: EncodingReason;
  vadStatus: VadStatus = "silence";
  negotiationStatus: TrackNegotiationStatus = "awaiting";

  // Indicates that metadata were changed when in "offered" negotiationStatus
  // and `updateTrackMetadata` Media Event should be sent after the transition to "done"
  pendingMetadataUpdate: boolean = false;

  constructor(endpoint: Endpoint, trackId: string, metadata: any, simulcastConfig: SimulcastConfig) {
    super();
    this.endpoint = endpoint;
    this.trackId = trackId;
    this.metadata = metadata;
    this.simulcastConfig = simulcastConfig;
  }
}

/**
 * Type describing possible track encodings.
 * - `"h"` - original encoding
 * - `"m"` - original encoding scaled down by 2
 * - `"l"` - original encoding scaled down by 4
 *
 * Notice that to make all encodings work, the initial
 * resolution has to be at least 1280x720.
 * In other case, browser might not be able to scale
 * some encodings down.
 */
export type TrackEncoding = "l" | "m" | "h";

/**
 * Events emitted by the {@link WebRTCEndpoint} instance.
 */
export interface WebRTCEndpointEvents {
  /**
   * Emitted each time WebRTCEndpoint need to send some data to the server.
   */
  sendMediaEvent: (mediaEvent: SerializedMediaEvent) => void;

  /**
   * Emitted when endpoint of this {@link WebRTCEndpoint} instance is ready. Triggered by {@link WebRTCEndpoint.connect}
   */
  connected: (endpointId: string, otherEndpoints: Endpoint[]) => void;

  /**
   * Emitted when endpoint of this {@link WebRTCEndpoint} instance was removed.
   */
  disconnected: () => void;

  /**
   * Emitted when data in a new track arrives.
   *
   * This event is always emitted after {@link trackAdded}.
   * It informs the user that data related to the given track arrives and can be played or displayed.
   */
  trackReady: (ctx: TrackContext) => void;

  /**
   * Emitted each time the endpoint which was already in the room, adds new track. Fields track and stream will be set to null.
   * These fields will be set to non-null value in {@link trackReady}
   */
  trackAdded: (ctx: TrackContext) => void;

  /**
   * Emitted when some track will no longer be sent.
   *
   * It will also be emitted before {@link endpointRemoved} for each track of this endpoint.
   */
  trackRemoved: (ctx: TrackContext) => void;

  /**
   * Emitted each time endpoint has its track metadata updated.
   */
  trackUpdated: (ctx: TrackContext) => void;

  /**
   * Emitted each time new endpoint is added to the room.
   */
  endpointAdded: (endpoint: Endpoint) => void;

  /**
   * Emitted each time endpoint is removed, emitted only for other endpoints.
   */
  endpointRemoved: (endpoint: Endpoint) => void;

  /**
   * Emitted each time endpoint has its metadata updated.
   */
  endpointUpdated: (endpoint: Endpoint) => void;

  /**
   * Emitted in case of errors related to multimedia session e.g. ICE connection.
   */
  connectionError: (message: string) => void;

  /**
   * Currently, this event is only emitted when DisplayManager in RTC Engine is
   * enabled and simulcast is disabled.
   *
   * Emitted when priority of video tracks have changed.
   * @param enabledTracks - list of tracks which will be sent to client from SFU
   * @param disabledTracks - list of tracks which will not be sent to client from SFU
   */
  tracksPriorityChanged: (enabledTracks: TrackContext[], disabledTracks: TrackContext[]) => void;

  /**
   * Emitted every time the server estimates client's bandwidth.
   *
   * @param {bigint} estimation - client's available incoming bitrate estimated
   * by the server. It's measured in bits per second.
   */
  bandwidthEstimationChanged: (estimation: bigint) => void;
}

/**
 * Main class that is responsible for connecting to the RTC Engine, sending and receiving media.
 */
export class WebRTCEndpoint extends (EventEmitter as new () => TypedEmitter<Required<WebRTCEndpointEvents>>) {
  private trackIdToTrack: Map<string, TrackContextImpl> = new Map();
  private connection?: RTCPeerConnection;
  private idToEndpoint: Map<string, Endpoint> = new Map();
  private localEndpoint: Endpoint = {
    id: "",
    type: "webrtc",
    metadata: {},
    tracks: new Map(),
  };
  private localTrackIdToTrack: Map<string, TrackContextImpl> = new Map();
  private midToTrackId: Map<string, string> = new Map();
  private disabledTrackEncodings: Map<string, TrackEncoding[]> = new Map();
  private rtcConfig: RTCConfiguration = {
    bundlePolicy: "max-bundle",
    iceServers: [],
    iceTransportPolicy: "relay",
  };

  // indicates that the ongoingRenegotiation of renegotiation is ongoing (renegotiateTracks, offerData, sdpOffer, sdpAnswer)
  private ongoingRenegotiation: boolean = false;
  private ongoingTrackReplacement: boolean = false;
  private commandsQueue: Command[] = [];

  constructor() {
    super();
  }

  /**
   * Tries to connect to the RTC Engine. If user is succesfully connected then {@link WebRTCEndpointEvents.connected}
   * will be emitted.
   *
   * @param metadata - Any information that other endpoints will receive in {@link WebRTCEndpointEvents.endpointAdded}
   * after accepting this endpoint
   *
   * @example
   * ```ts
   * let webrtc = new WebRTCEndpoint();
   * webrtc.connect({displayName: "Bob"});
   * ```
   */
  public connect = (metadata: any): void => {
    this.localEndpoint.metadata = metadata;
    const mediaEvent = generateMediaEvent("connect", {
      metadata: metadata,
    });
    this.sendMediaEvent(mediaEvent);
  };

  /**
   * Feeds media event received from RTC Engine to {@link WebRTCEndpoint}.
   * This function should be called whenever some media event from RTC Engine
   * was received and can result in {@link WebRTCEndpoint} generating some other
   * media events.
   *
   * @param mediaEvent - String data received over custom signalling layer.
   *
   * @example
   * This example assumes phoenix channels as signalling layer.
   * As phoenix channels require objects, RTC Engine encapsulates binary data into
   * map with one field that is converted to object with one field on the TS side.
   * ```ts
   * webrtcChannel.on("mediaEvent", (event) => webrtc.receiveMediaEvent(event.data));
   * ```
   */
  public receiveMediaEvent = (mediaEvent: SerializedMediaEvent) => {
    const deserializedMediaEvent = deserializeMediaEvent(mediaEvent);
    switch (deserializedMediaEvent.type) {
      case "connected": {
        this.localEndpoint.id = deserializedMediaEvent.data.id;

        this.emit("connected", deserializedMediaEvent.data.id, deserializedMediaEvent.data.otherEndpoints);

        const endpoints: any[] = deserializedMediaEvent.data.otherEndpoints;
        const otherEndpoints: Endpoint[] = endpoints.map((endpoint) => {
          endpoint.tracks = this.mapMediaEventTracksToTrackContextImpl(Array.from(endpoint.tracks), endpoint);

          this.addEndpoint(endpoint);
          return endpoint;
        });

        otherEndpoints.forEach((endpoint) => {
          Array.from(endpoint.tracks.entries()).forEach(([trackId, ctx]) => {
            this.trackIdToTrack.set(trackId, ctx);

            this.emit("trackAdded", ctx);
          });
        });
        break;
      }
      default:
        if (this.localEndpoint.id != null) this.handleMediaEvent(deserializedMediaEvent);
    }
  };

  /**
   * Returns a snapshot of currently received remote tracks.
   *
   * @example
   * if (webRTCEndpoint.getRemoteTracks()[trackId]?.simulcastConfig?.enabled) {
   *   webRTCEndpoint.setTargetTrackEncoding(trackId, encoding);
   * }
   */
  public getRemoteTracks(): Record<string, TrackContext> {
    return Object.fromEntries(this.trackIdToTrack.entries());
  }

  /**
   * Returns a snapshot of currently received remote endpoints.
   */
  public getRemoteEndpoints(): Record<string, Endpoint> {
    return Object.fromEntries(this.idToEndpoint.entries());
  }

  private handleMediaEvent = (deserializedMediaEvent: MediaEvent) => {
    let endpoint: Endpoint;
    let data;
    switch (deserializedMediaEvent.type) {
      case "offerData": {
        const turnServers = deserializedMediaEvent.data.integratedTurnServers;
        this.setTurns(turnServers);

        const offerData = new Map<string, number>(Object.entries(deserializedMediaEvent.data.tracksTypes));

        this.onOfferData(offerData);
        break;
      }
      case "tracksAdded": {
        this.ongoingRenegotiation = true;

        data = deserializedMediaEvent.data;
        if (this.getEndpointId() === data.endpointId) return;
        data.tracks = new Map<string, any>(Object.entries(data.tracks));
        endpoint = this.idToEndpoint.get(data.endpointId)!;
        const oldTracks = endpoint.tracks;

        data.tracks = this.mapMediaEventTracksToTrackContextImpl(data.tracks, endpoint);

        endpoint.tracks = new Map([...endpoint.tracks, ...data.tracks]);

        this.idToEndpoint.set(endpoint.id, endpoint);
        Array.from(endpoint.tracks.entries()).forEach(([trackId, ctx]) => {
          if (!oldTracks.has(trackId)) {
            this.trackIdToTrack.set(trackId, ctx);

            this.emit("trackAdded", ctx);
          }
        });
        break;
      }
      case "tracksRemoved": {
        this.ongoingRenegotiation = true;

        data = deserializedMediaEvent.data;
        const endpointId = data.endpointId;
        if (this.getEndpointId() === endpointId) return;
        const trackIds = data.trackIds as string[];
        trackIds.forEach((trackId) => {
          const trackContext = this.trackIdToTrack.get(trackId)!;

          this.eraseTrack(trackId, endpointId);

          this.emit("trackRemoved", trackContext);
        });
        break;
      }

      case "sdpAnswer":
        this.midToTrackId = new Map(Object.entries(deserializedMediaEvent.data.midToTrackId));

        for (const trackId of Object.values(deserializedMediaEvent.data.midToTrackId)) {
          const track = this.localTrackIdToTrack.get(trackId as string);
          // if is local track
          if (track) {
            track.negotiationStatus = "done";

            if (track.pendingMetadataUpdate) {
              const mediaEvent = generateMediaEvent("updateTrackMetadata", {
                trackId,
                trackMetadata: track.metadata,
              });
              this.sendMediaEvent(mediaEvent);
            }

            track.pendingMetadataUpdate = false;
          }
        }

        this.onAnswer(deserializedMediaEvent.data);

        this.ongoingRenegotiation = false;
        this.processNextCommand();
        break;

      case "candidate":
        this.onRemoteCandidate(deserializedMediaEvent.data);
        break;

      case "endpointAdded":
        endpoint = deserializedMediaEvent.data;
        if (endpoint.id === this.getEndpointId()) return;
        this.addEndpoint(endpoint);

        this.emit("endpointAdded", endpoint);
        break;

      case "endpointRemoved":
        if (deserializedMediaEvent.data.id === this.localEndpoint.id) {
          this.cleanUp();
          this.emit("disconnected");
          return;
        }

        endpoint = this.idToEndpoint.get(deserializedMediaEvent.data.id)!;
        if (endpoint === undefined) return;

        Array.from(endpoint.tracks.keys()).forEach((trackId) => {
          this.emit("trackRemoved", this.trackIdToTrack.get(trackId)!);
        });

        this.eraseEndpoint(endpoint);

        this.emit("endpointRemoved", endpoint);
        break;

      case "endpointUpdated":
        if (this.getEndpointId() === deserializedMediaEvent.data.id) return;
        endpoint = this.idToEndpoint.get(deserializedMediaEvent.data.id)!;
        endpoint.metadata = deserializedMediaEvent.data.metadata;
        this.addEndpoint(endpoint);

        this.emit("endpointUpdated", endpoint);
        break;

      case "trackUpdated": {
        if (this.getEndpointId() === deserializedMediaEvent.data.endpointId) return;

        endpoint = this.idToEndpoint.get(deserializedMediaEvent.data.endpointId)!;
        if (endpoint == null) throw `Endpoint with id: ${deserializedMediaEvent.data.endpointId} doesn't exist`;

        const trackId = deserializedMediaEvent.data.trackId;
        const trackMetadata = deserializedMediaEvent.data.metadata;
        const prevTrack = endpoint.tracks.get(trackId)!;
        endpoint.tracks.set(trackId, { ...prevTrack, metadata: trackMetadata });
        const trackContext = this.trackIdToTrack.get(trackId)!;
        trackContext.metadata = trackMetadata;

        this.emit("trackUpdated", trackContext);
        break;
      }

      case "tracksPriority": {
        const enabledTracks = (deserializedMediaEvent.data.tracks as string[]).map(
          (trackId) => this.trackIdToTrack.get(trackId)!,
        );

        const disabledTracks = Array.from(this.trackIdToTrack.values()).filter(
          (track) => !enabledTracks.includes(track),
        );

        this.emit("tracksPriorityChanged", enabledTracks, disabledTracks);
        break;
      }
      case "encodingSwitched": {
        const trackId = deserializedMediaEvent.data.trackId;
        const trackContext = this.trackIdToTrack.get(trackId)!;
        trackContext.encoding = deserializedMediaEvent.data.encoding;
        trackContext.encodingReason = deserializedMediaEvent.data.reason;

        trackContext.emit("encodingChanged", trackContext);
        break;
      }
      case "custom":
        this.handleMediaEvent(deserializedMediaEvent.data as MediaEvent);
        break;

      case "error":
        this.emit("connectionError", deserializedMediaEvent.data.message);

        this.disconnect();
        break;

      case "vadNotification": {
        const trackId = deserializedMediaEvent.data.trackId;
        const ctx = this.trackIdToTrack.get(trackId)!;
        const vadStatus = deserializedMediaEvent.data.status;
        if (vadStatuses.includes(vadStatus)) {
          ctx.vadStatus = vadStatus;
          ctx.emit("voiceActivityChanged", ctx);
        } else {
          console.warn("Received unknown vad status: ", vadStatus);
        }
        break;
      }

      case "bandwidthEstimation": {
        const estimation = deserializedMediaEvent.data.estimation;

        this.emit("bandwidthEstimationChanged", estimation as bigint);
        break;
      }

      default:
        console.warn("Received unknown media event: ", deserializedMediaEvent.type);
        break;
    }
  };

  /**
   * Adds track that will be sent to the RTC Engine.
   * @param track - Audio or video track e.g. from your microphone or camera.
   * @param stream  - Stream that this track belongs to.
   * @param trackMetadata - Any information about this track that other endpoints will
   * receive in {@link WebRTCEndpointEvents.endpointAdded}. E.g. this can source of the track - whether it's
   * screensharing, webcam or some other media device.
   * @param simulcastConfig - Simulcast configuration. By default simulcast is disabled.
   * For more information refer to {@link SimulcastConfig}.
   * @param maxBandwidth - maximal bandwidth this track can use.
   * Defaults to 0 which is unlimited.
   * This option has no effect for simulcast and audio tracks.
   * For simulcast tracks use `{@link WebRTCEndpoint.setTrackBandwidth}.
   * @returns {string} Returns id of added track
   * @example
   * ```ts
   * let localStream: MediaStream = new MediaStream();
   * try {
   *   localAudioStream = await navigator.mediaDevices.getUserMedia(
   *     AUDIO_CONSTRAINTS
   *   );
   *   localAudioStream
   *     .getTracks()
   *     .forEach((track) => localStream.addTrack(track));
   * } catch (error) {
   *   console.error("Couldn't get microphone permission:", error);
   * }
   *
   * try {
   *   localVideoStream = await navigator.mediaDevices.getUserMedia(
   *     VIDEO_CONSTRAINTS
   *   );
   *   localVideoStream
   *     .getTracks()
   *     .forEach((track) => localStream.addTrack(track));
   * } catch (error) {
   *  console.error("Couldn't get camera permission:", error);
   * }
   *
   * localStream
   *  .getTracks()
   *  .forEach((track) => webrtc.addTrack(track, localStream));
   * ```
   */
  public addTrack(
    track: MediaStreamTrack,
    stream: MediaStream,
    trackMetadata: any = new Map(),
    simulcastConfig: SimulcastConfig = { enabled: false, activeEncodings: [] },
    maxBandwidth: TrackBandwidthLimit = 0, // unlimited bandwidth
  ): string {
    const isUsedTrack = this.connection?.getSenders().some((val) => val.track === track);

    if (isUsedTrack) {
      throw "This track was already added to peerConnection, it can't be added again!";
    }

    if (!simulcastConfig.enabled && !(typeof maxBandwidth === "number"))
      throw "Invalid type of `maxBandwidth` argument for a non-simulcast track, expected: number";
    if (this.getEndpointId() === "") throw "Cannot add tracks before being accepted by the server";
    const trackId = this.getTrackId(uuidv4());

    this.pushCommand({
      commandType: "ADD-TRACK",
      trackId,
      track,
      stream,
      trackMetadata,
      simulcastConfig,
      maxBandwidth,
    });

    return trackId;
  }

  private pushCommand(command: Command) {
    this.commandsQueue.push(command);
    this.processNextCommand();
  }

  private handleCommand(command: Command) {
    switch (command.commandType) {
      case "ADD-TRACK":
        this.addTrackCommandHandler(command);
        break;
      case "REMOVE-TRACK":
        this.removeTrackHandler(command);
        break;
      case "REPLACE-TRACK":
        this.replaceTrackHandler(command);
        break;
    }
  }

  private processNextCommand() {
    if (this.ongoingRenegotiation || this.ongoingTrackReplacement) return;

    if (
      this.connection &&
      (this.connection.signalingState !== "stable" ||
        this.connection.connectionState !== "connected" ||
        this.connection.iceConnectionState !== "connected")
    )
      return;

    const command = this.commandsQueue.shift();

    if (!command) return;

    this.handleCommand(command);
  }

  private addTrackCommandHandler(addTrackCommand: AddTrackCommand): string {
    const { simulcastConfig, maxBandwidth, track, stream, trackMetadata, trackId } = addTrackCommand;
    const isUsedTrack = this.connection?.getSenders().some((val) => val.track === track);

    if (isUsedTrack) {
      throw "This track was already added to peerConnection, it can't be added again!";
    }

    if (!simulcastConfig.enabled && !(typeof maxBandwidth === "number"))
      throw "Invalid type of `maxBandwidth` argument for a non-simulcast track, expected: number";
    if (this.getEndpointId() === "") throw "Cannot add tracks before being accepted by the server";

    this.ongoingRenegotiation = true;

    const trackContext = new TrackContextImpl(this.localEndpoint, trackId, trackMetadata, simulcastConfig);

    this.localEndpoint.tracks.set(trackId, trackContext);

    trackContext.track = track;
    trackContext.stream = stream;
    trackContext.maxBandwidth = maxBandwidth;

    this.localTrackIdToTrack.set(trackId, trackContext);

    if (this.connection) {
      this.addTrackToConnection(trackContext);

      this.connection
        .getTransceivers()
        .forEach(
          (transceiver) =>
            (transceiver.direction = transceiver.direction === "sendrecv" ? "sendonly" : transceiver.direction),
        );
    }

    const mediaEvent = generateCustomEvent({ type: "renegotiateTracks" });
    this.sendMediaEvent(mediaEvent);
    return trackId;
  }

  private addTrackToConnection = (trackContext: TrackContext) => {
    const transceiverConfig = this.createTransceiverConfig(trackContext);
    const track = trackContext.track!;
    this.connection!.addTransceiver(track, transceiverConfig);
  };

  private createTransceiverConfig(trackContext: TrackContext): RTCRtpTransceiverInit {
    let transceiverConfig: RTCRtpTransceiverInit;

    if (trackContext.track!.kind === "audio") {
      transceiverConfig = this.createAudioTransceiverConfig(trackContext);
    } else {
      transceiverConfig = this.createVideoTransceiverConfig(trackContext);
    }

    return transceiverConfig;
  }

  private createAudioTransceiverConfig(_trackContext: TrackContext): RTCRtpTransceiverInit {
    return { direction: "sendonly" };
  }

  private createVideoTransceiverConfig(trackContext: TrackContext): RTCRtpTransceiverInit {
    let transceiverConfig: RTCRtpTransceiverInit;
    if (trackContext.simulcastConfig!.enabled) {
      transceiverConfig = simulcastTransceiverConfig;
      const trackActiveEncodings = trackContext.simulcastConfig!.activeEncodings;
      const disabledTrackEncodings: TrackEncoding[] = [];
      transceiverConfig.sendEncodings?.forEach((encoding) => {
        if (trackActiveEncodings.includes(encoding.rid! as TrackEncoding)) {
          encoding.active = true;
        } else {
          disabledTrackEncodings.push(encoding.rid! as TrackEncoding);
        }
      });
      this.disabledTrackEncodings.set(trackContext.trackId, disabledTrackEncodings);
    } else {
      transceiverConfig = {
        direction: "sendonly",
        sendEncodings: [
          {
            active: true,
          },
        ],
      };
    }

    if (trackContext.maxBandwidth && transceiverConfig.sendEncodings)
      this.applyBandwidthLimitation(transceiverConfig.sendEncodings, trackContext.maxBandwidth);

    return transceiverConfig;
  }

  private applyBandwidthLimitation(encodings: RTCRtpEncodingParameters[], max_bandwidth: TrackBandwidthLimit) {
    if (typeof max_bandwidth === "number") {
      // non-simulcast limitation
      this.splitBandwidth(encodings, (max_bandwidth as number) * 1024);
    } else {
      // simulcast bandwidth limit
      encodings
        .filter((encoding) => encoding.rid)
        .forEach((encoding) => {
          const limit = (max_bandwidth as SimulcastBandwidthLimit).get(encoding.rid! as TrackEncoding) || 0;

          if (limit > 0) {
            encoding.maxBitrate = limit * 1024;
          } else delete encoding.maxBitrate;
        });
    }
  }

  private splitBandwidth(encodings: RTCRtpEncodingParameters[], bandwidth: number) {
    if (bandwidth === 0) {
      encodings.forEach((encoding) => delete encoding.maxBitrate);
      return;
    }

    if (encodings.length == 0) {
      // This most likely is a race condition. Log an error and prevent catastrophic failure
      console.error("Attempted to limit bandwidth of the track that doesn't have any encodings");
      return;
    }

    // We are solving the following equation:
    // x + (k0/k1)^2 * x + (k0/k2)^2 * x + ... + (k0/kn)^2 * x = bandwidth
    // where x is the bitrate for the first encoding, kn are scaleResolutionDownBy factors
    // square is dictated by the fact that k0/kn is a scale factor, but we are interested in the total number of pixels in the image
    const firstScaleDownBy = encodings![0].scaleResolutionDownBy || 1;
    const bitrate_parts = encodings.reduce(
      (acc, value) => acc + (firstScaleDownBy / (value.scaleResolutionDownBy || 1)) ** 2,
      0,
    );
    const x = bandwidth / bitrate_parts;

    encodings.forEach((value) => {
      value.maxBitrate = x * (firstScaleDownBy / (value.scaleResolutionDownBy || 1)) ** 2;
    });
  }

  /**
   * Replaces a track that is being sent to the RTC Engine.
   * @param trackId - Audio or video track.
   * @param {string} trackId - Id of audio or video track to replace.
   * @param {MediaStreamTrack} newTrack
   * @param {any} [newTrackMetadata] - Optional track metadata to apply to the new track. If no
   *                              track metadata is passed, the old track metadata is retained.
   * @returns {Promise<boolean>} success
   * @example
   * ```ts
   * // setup camera
   * let localStream: MediaStream = new MediaStream();
   * try {
   *   localVideoStream = await navigator.mediaDevices.getUserMedia(
   *     VIDEO_CONSTRAINTS
   *   );
   *   localVideoStream
   *     .getTracks()
   *     .forEach((track) => localStream.addTrack(track));
   * } catch (error) {
   *   console.error("Couldn't get camera permission:", error);
   * }
   * let oldTrackId;
   * localStream
   *  .getTracks()
   *  .forEach((track) => trackId = webrtc.addTrack(track, localStream));
   *
   * // change camera
   * const oldTrack = localStream.getVideoTracks()[0];
   * let videoDeviceId = "abcd-1234";
   * navigator.mediaDevices.getUserMedia({
   *      video: {
   *        ...(VIDEO_CONSTRAINTS as {}),
   *        deviceId: {
   *          exact: videoDeviceId,
   *        },
   *      }
   *   })
   *   .then((stream) => {
   *     let videoTrack = stream.getVideoTracks()[0];
   *     webrtc.replaceTrack(oldTrackId, videoTrack);
   *   })
   *   .catch((error) => {
   *     console.error('Error switching camera', error);
   *   })
   * ```
   */
  public async replaceTrack(trackId: string, newTrack: MediaStreamTrack, newTrackMetadata?: any): Promise<boolean> {
    const result = new Deferred<boolean>();

    this.pushCommand({
      commandType: "REPLACE-TRACK",
      trackId,
      newTrack,
      newTrackMetadata,
      result,
    });

    return result.promise;
  }

  private replaceTrackHandler(command: ReplaceTackCommand) {
    const { trackId, newTrack, newTrackMetadata, result } = command;

    const trackContext = this.localTrackIdToTrack.get(trackId)!;
    const sender = this.findSender(trackContext.track!.id);
    if (sender) {
      this.ongoingTrackReplacement = true;
      sender
        .replaceTrack(newTrack)
        .then(() => {
          const trackMetadata = newTrackMetadata || this.localTrackIdToTrack.get(trackId)!.metadata;
          trackContext.track = newTrack;
          this.updateTrackMetadata(trackId, trackMetadata);
          result.resolve(true);
        })
        .catch(() => {
          result.resolve(false);
        })
        .finally(() => {
          this.ongoingTrackReplacement = false;
          this.processNextCommand();
        });
    }
  }

  /**
   * Updates maximum bandwidth for the track identified by trackId.
   * This value directly translates to quality of the stream and, in case of video, to the amount of RTP packets being sent.
   * In case trackId points at the simulcast track bandwidth is split between all of the variant streams proportionally to their resolution.
   *
   * @param {string} trackId
   * @param {BandwidthLimit} bandwidth in kbps
   * @returns {Promise<boolean>} success
   */
  public setTrackBandwidth(trackId: string, bandwidth: BandwidthLimit): Promise<boolean> {
    // FIXME: maxBandwidth in TrackContext is not updated
    const trackContext = this.localTrackIdToTrack.get(trackId);

    if (!trackContext) {
      return Promise.reject(`Track '${trackId}' doesn't exist`);
    }

    const sender = this.findSender(trackContext.track!.id);
    const parameters = sender.getParameters();

    if (parameters.encodings.length === 0) {
      parameters.encodings = [{}];
    } else {
      this.applyBandwidthLimitation(parameters.encodings, bandwidth);
    }

    return sender
      .setParameters(parameters)
      .then(() => {
        const mediaEvent = generateCustomEvent({
          type: "trackVariantBitrates",
          data: {
            trackId: trackId,
            variantBitrates: this.getTrackBitrates(trackId),
          },
        });
        this.sendMediaEvent(mediaEvent);
        return true;
      })
      .catch((_error) => false);
  }

  /**
   * Updates maximum bandwidth for the given simulcast encoding of the given track.
   *
   * @param {string} trackId - id of the track
   * @param {string} rid - rid of the encoding
   * @param {BandwidthLimit} bandwidth - desired max bandwidth used by the encoding (in kbps)
   * @returns
   */
  public setEncodingBandwidth(trackId: string, rid: string, bandwidth: BandwidthLimit): Promise<boolean> {
    const trackContext = this.localTrackIdToTrack.get(trackId)!;

    if (!trackContext) {
      return Promise.reject(`Track '${trackId}' doesn't exist`);
    }

    const sender = this.findSender(trackContext.track!.id);
    const parameters = sender.getParameters();
    const encoding = parameters.encodings.find((encoding) => encoding.rid === rid);

    if (!encoding) {
      return Promise.reject(`Encoding with rid '${rid}' doesn't exist`);
    } else if (bandwidth === 0) {
      delete encoding.maxBitrate;
    } else {
      encoding.maxBitrate = bandwidth * 1024;
    }

    return sender
      .setParameters(parameters)
      .then(() => {
        const mediaEvent = generateCustomEvent({
          type: "trackVariantBitrates",
          data: {
            trackId: trackId,
            variantBitrates: this.getTrackBitrates(trackId),
          },
        });
        this.sendMediaEvent(mediaEvent);
        return true;
      })
      .catch((_error) => false);
  }

  /**
   * Removes a track from connection that was sent to the RTC Engine.
   * @param {string} trackId - Id of audio or video track to remove.
   * @example
   * ```ts
   * // setup camera
   * let localStream: MediaStream = new MediaStream();
   * try {
   *   localVideoStream = await navigator.mediaDevices.getUserMedia(
   *     VIDEO_CONSTRAINTS
   *   );
   *   localVideoStream
   *     .getTracks()
   *     .forEach((track) => localStream.addTrack(track));
   * } catch (error) {
   *   console.error("Couldn't get camera permission:", error);
   * }
   *
   * let trackId
   * localStream
   *  .getTracks()
   *  .forEach((track) => trackId = webrtc.addTrack(track, localStream));
   *
   * // remove track
   * webrtc.removeTrack(trackId)
   * ```
   */
  public removeTrack(trackId: string) {
    this.pushCommand({
      commandType: "REMOVE-TRACK",
      trackId,
    });
  }

  private removeTrackHandler(command: RemoveTrackCommand) {
    const { trackId } = command;
    const trackContext = this.localTrackIdToTrack.get(trackId)!;
    const sender = this.findSender(trackContext.track!.id);

    this.ongoingRenegotiation = true;

    this.connection!.removeTrack(sender);
    const mediaEvent = generateCustomEvent({ type: "renegotiateTracks" });
    this.sendMediaEvent(mediaEvent);
    this.localTrackIdToTrack.delete(trackId);
    this.localEndpoint.tracks.delete(trackId);
  }

  /**
   * Currently, this function only works when DisplayManager in RTC Engine is
   * enabled and simulcast is disabled.
   *
   * Prioritizes a track in connection to be always sent to browser.
   *
   * @param {string} trackId - Id of video track to prioritize.
   */
  public prioritizeTrack(trackId: string) {
    const mediaEvent = generateCustomEvent({
      type: "prioritizeTrack",
      data: { trackId },
    });
    this.sendMediaEvent(mediaEvent);
  }

  /**
   * Currently, this function only works when DisplayManager in RTC Engine is
   * enabled and simulcast is disabled.
   *
   * Unprioritizes a track.
   *
   * @param {string} trackId - Id of video track to unprioritize.
   */
  public unprioritizeTrack(trackId: string) {
    const mediaEvent = generateCustomEvent({
      type: "unprioritizeTrack",
      data: { trackId },
    });
    this.sendMediaEvent(mediaEvent);
  }

  /**
   * Currently this function has no effect.
   *
   * This function allows to adjust resolution and number of video tracks sent by an SFU to a client.
   *
   * @param {number} bigScreens - number of screens with big size
   * (if simulcast is used this will limit number of tracks sent with highest quality).
   * @param {number} smallScreens - number of screens with small size
   * (if simulcast is used this will limit number of tracks sent with lowest quality).
   * @param {number} mediumScreens - number of screens with medium size
   * (if simulcast is used this will limit number of tracks sent with medium quality).
   * @param {boolean} allSameSize - flag that indicates whether all screens should use the same quality
   */
  public setPreferedVideoSizes(
    bigScreens: number,
    smallScreens: number,
    mediumScreens: number = 0,
    allSameSize: boolean = false,
  ) {
    const mediaEvent = generateCustomEvent({
      type: "preferedVideoSizes",
      data: { bigScreens, mediumScreens, smallScreens, allSameSize },
    });
    this.sendMediaEvent(mediaEvent);
  }

  /**
   * Sets track encoding that server should send to the client library.
   *
   * The encoding will be sent whenever it is available.
   * If chosen encoding is temporarily unavailable, some other encoding
   * will be sent until the chosen encoding becomes active again.
   *
   * @param {string} trackId - id of track
   * @param {TrackEncoding} encoding - encoding to receive
   * @example
   * ```ts
   * webrtc.setTargetTrackEncoding(incomingTrackCtx.trackId, "l")
   * ```
   */
  public setTargetTrackEncoding(trackId: string, encoding: TrackEncoding) {
    const trackContext = this.trackIdToTrack.get(trackId);
    if (!trackContext?.simulcastConfig?.enabled || !trackContext.simulcastConfig.activeEncodings.includes(encoding)) {
      console.warn("The track does not support changing its target encoding");
      return;
    }
    const mediaEvent = generateCustomEvent({
      type: "setTargetTrackVariant",
      data: {
        trackId: trackId,
        variant: encoding,
      },
    });

    this.sendMediaEvent(mediaEvent);
  }

  /**
   * Enables track encoding so that it will be sent to the server.
   * @param {string} trackId - id of track
   * @param {TrackEncoding} encoding - encoding that will be enabled
   * @example
   * ```ts
   * const trackId = webrtc.addTrack(track, stream, {}, {enabled: true, activeEncodings: ["l", "m", "h"]});
   * webrtc.disableTrackEncoding(trackId, "l");
   * // wait some time
   * webrtc.enableTrackEncoding(trackId, "l");
   * ```
   */
  public enableTrackEncoding(trackId: string, encoding: TrackEncoding) {
    const track = this.localTrackIdToTrack.get(trackId)?.track;
    // eslint-disable-next-line @typescript-eslint/no-non-null-asserted-optional-chain
    const newDisabledTrackEncodings = this.disabledTrackEncodings.get(trackId)?.filter((en) => en !== encoding)!;
    this.disabledTrackEncodings.set(trackId, newDisabledTrackEncodings);
    const sender = this.connection?.getSenders().filter((sender) => sender.track === track)[0];
    const params = sender?.getParameters();
    params!.encodings.filter((en) => en.rid == encoding)[0].active = true;
    sender?.setParameters(params!);
  }

  /**
   * Disables track encoding so that it will be no longer sent to the server.
   * @param {string} trackId - id of track
   * @param {rackEncoding} encoding - encoding that will be disabled
   * @example
   * ```ts
   * const trackId = webrtc.addTrack(track, stream, {}, {enabled: true, activeEncodings: ["l", "m", "h"]});
   * webrtc.disableTrackEncoding(trackId, "l");
   * ```
   */
  public disableTrackEncoding(trackId: string, encoding: TrackEncoding) {
    const track = this.localTrackIdToTrack.get(trackId)?.track;
    this.disabledTrackEncodings.get(trackId)!.push(encoding);
    const sender = this.connection?.getSenders().filter((sender) => sender.track === track)[0];
    const params = sender?.getParameters();
    params!.encodings.filter((en) => en.rid == encoding)[0].active = false;
    sender?.setParameters(params!);
  }

  private findSender(trackId: string): RTCRtpSender {
    return this.connection!.getSenders().find((sender) => sender.track && sender!.track!.id === trackId)!;
  }

  /**
   * Updates the metadata for the current endpoint.
   * @param metadata - Data about this endpoint that other endpoints will receive upon being added.
   *
   * If the metadata is different from what is already tracked in the room, the optional
   * event `endpointUpdated` will be emitted for other endpoint in the room.
   */
  public updateEndpointMetadata = (metadata: any): void => {
    const mediaEvent = generateMediaEvent("updateEndpointMetadata", {
      metadata: metadata,
    });
    this.sendMediaEvent(mediaEvent);
  };

  /**
   * Updates the metadata for a specific track.
   * @param trackId - trackId (generated in addTrack) of audio or video track.
   * @param trackMetadata - Data about this track that other endpoint will receive upon being added.
   *
   * If the metadata is different from what is already tracked in the room, the optional
   * event `trackUpdated` will be emitted for other endpoints in the room.
   */
  public updateTrackMetadata = (trackId: string, trackMetadata: any): void => {
    const trackContext = this.localTrackIdToTrack.get(trackId)!;
    trackContext.metadata = trackMetadata;
    this.localTrackIdToTrack.set(trackId, trackContext);

    const prevTrack = this.localEndpoint.tracks.get(trackId)!;

    this.localEndpoint.tracks.set(trackId, { ...prevTrack, metadata: trackMetadata });
    const mediaEvent = generateMediaEvent("updateTrackMetadata", {
      trackId,
      trackMetadata,
    });

    switch (trackContext.negotiationStatus) {
      case "done":
        this.sendMediaEvent(mediaEvent);
        break;

      case "offered":
        trackContext.pendingMetadataUpdate = true;
        break;

      case "awaiting":
        // We don't need to do anything
        break;
    }
  };

  private getMidToTrackId = () => {
    const localTrackMidToTrackId = {} as any;

    if (!this.connection) return null;
    this.connection.getTransceivers().forEach((transceiver) => {
      const localTrackId = transceiver.sender.track?.id;
      const mid = transceiver.mid;
      if (localTrackId && mid) {
        const trackContext = Array.from(this.localTrackIdToTrack.values()).find(
          (trackContext) => trackContext!.track!.id === localTrackId,
        )!;
        localTrackMidToTrackId[mid] = trackContext.trackId;
      }
    });
    return localTrackMidToTrackId;
  };

  /**
   * Disconnects from the room. This function should be called when user disconnects from the room
   * in a clean way e.g. by clicking a dedicated, custom button `disconnect`.
   * As a result there will be generated one more media event that should be
   * sent to the RTC Engine. Thanks to it each other endpoint will be notified
   * that endpoint was removed in {@link WebRTCEndpointEvents.endpointRemoved},
   */
  public disconnect = () => {
    const mediaEvent = generateMediaEvent("disconnect");
    this.sendMediaEvent(mediaEvent);
    this.cleanUp();
  };

  /**
   * Cleans up {@link WebRTCEndpoint} instance.
   */
  public cleanUp = () => {
    if (this.connection) {
      this.connection.onicecandidate = null;
      this.connection.ontrack = null;
      this.connection.onconnectionstatechange = null;
      this.connection.onicecandidateerror = null;
      this.connection.oniceconnectionstatechange = null;
    }

    this.connection = undefined;
  };

  private getTrackId(uuid: string): string {
    return `${this.getEndpointId()}:${uuid}`;
  }

  private sendMediaEvent = (mediaEvent: MediaEvent) => {
    const serializedMediaEvent = serializeMediaEvent(mediaEvent);
    this.emit("sendMediaEvent", serializedMediaEvent);
  };

  private onAnswer = async (answer: RTCSessionDescriptionInit) => {
    this.connection!.ontrack = this.onTrack();
    try {
      await this.connection!.setRemoteDescription(answer);
      this.disabledTrackEncodings.forEach((encodings: TrackEncoding[], trackId: string) => {
        encodings.forEach((encoding: TrackEncoding) => this.disableTrackEncoding(trackId, encoding));
      });
    } catch (err) {
      console.error(err);
    }
  };

  private addTransceiversIfNeeded = (serverTracks: Map<string, number>) => {
    const recvTransceivers = this.connection!.getTransceivers().filter((elem) => elem.direction === "recvonly");
    let toAdd: string[] = [];

    const getNeededTransceiversTypes = (type: string): string[] => {
      let typeNumber = serverTracks.get(type);
      typeNumber = typeNumber !== undefined ? typeNumber : 0;
      const typeTransceiversNumber = recvTransceivers.filter((elem) => elem.receiver.track.kind === type).length;
      return Array(typeNumber - typeTransceiversNumber).fill(type);
    };

    const audio = getNeededTransceiversTypes("audio");
    const video = getNeededTransceiversTypes("video");
    toAdd = toAdd.concat(audio);
    toAdd = toAdd.concat(video);

    for (const kind of toAdd) this.connection?.addTransceiver(kind, { direction: "recvonly" });
  };

  private async createAndSendOffer() {
    if (!this.connection) return;
    try {
      const offer = await this.connection.createOffer();
      await this.connection.setLocalDescription(offer);

      const mediaEvent = generateCustomEvent({
        type: "sdpOffer",
        data: {
          sdpOffer: offer,
          trackIdToTrackMetadata: this.getTrackIdToMetadata(),
          trackIdToTrackBitrates: this.getTrackIdToTrackBitrates(),
          midToTrackId: this.getMidToTrackId(),
        },
      });
      this.sendMediaEvent(mediaEvent);

      for (const track of this.localTrackIdToTrack.values()) {
        track.negotiationStatus = "offered";
      }
    } catch (error) {
      console.error(error);
    }
  }

  private getTrackIdToMetadata = () => {
    const trackIdToMetadata = {} as any;
    Array.from(this.localEndpoint.tracks.entries()).forEach(([trackId, { metadata }]) => {
      trackIdToMetadata[trackId] = metadata;
    });
    return trackIdToMetadata;
  };

  private getTrackBitrates = (trackId: string) => {
    const trackContext = this.localTrackIdToTrack.get(trackId);
    if (!trackContext) throw "Track with id ${trackId} not present in 'localTrackIdToTrack'";
    const kind = trackContext.track!.kind as "audio" | "video";
    const sender = this.findSender(trackContext.track!.id);
    const encodings = sender.getParameters().encodings;

    if (encodings.length == 1 && !encodings[0].rid) return encodings[0].maxBitrate || defaultBitrates[kind];
    else if (kind == "audio") throw "Audio track cannot have multiple encodings";

    const bitrates = {} as any;

    encodings
      .filter((encoding) => encoding.rid)
      .forEach((encoding) => {
        const rid = encoding.rid! as TrackEncoding;
        bitrates[rid] = encoding.maxBitrate || defaultSimulcastBitrates[rid];
      });

    return bitrates;
  };

  private getTrackIdToTrackBitrates = () => {
    const trackIdToTrackBitrates = {} as any;

    Array.from(this.localEndpoint.tracks.entries()).forEach(([trackId, _trackEntry]) => {
      trackIdToTrackBitrates[trackId] = this.getTrackBitrates(trackId);
    });

    return trackIdToTrackBitrates;
  };

  private checkIfTrackBelongToEndpoint = (trackId: string, endpoint: Endpoint) =>
    Array.from(endpoint.tracks.keys()).some((track) => trackId.startsWith(track));

  private onOfferData = async (offerData: Map<string, number>) => {
    if (!this.connection) {
      this.connection = new RTCPeerConnection(this.rtcConfig);
      this.connection.onicecandidate = this.onLocalCandidate();
      this.connection.onicecandidateerror = this.onIceCandidateError as (event: Event) => void;
      this.connection.onconnectionstatechange = this.onConnectionStateChange;
      this.connection.oniceconnectionstatechange = this.onIceConnectionStateChange;
      this.connection.onicegatheringstatechange = this.onIceGatheringStateChange;
      this.connection.onsignalingstatechange = this.onSignalingStateChange;

      Array.from(this.localTrackIdToTrack.values()).forEach((trackContext) => this.addTrackToConnection(trackContext));

      this.connection.getTransceivers().forEach((transceiver) => (transceiver.direction = "sendonly"));
    } else {
      await this.connection.restartIce();
    }

    this.addTransceiversIfNeeded(offerData);

    await this.createAndSendOffer();
  };

  private onRemoteCandidate = (candidate: RTCIceCandidate) => {
    try {
      const iceCandidate = new RTCIceCandidate(candidate);
      if (!this.connection) {
        throw new Error("Received new remote candidate but RTCConnection is undefined");
      }
      this.connection.addIceCandidate(iceCandidate);
    } catch (error) {
      console.error(error);
    }
  };

  private onLocalCandidate = () => {
    return (event: RTCPeerConnectionIceEvent) => {
      if (event.candidate) {
        const mediaEvent = generateCustomEvent({
          type: "candidate",
          data: {
            candidate: event.candidate.candidate,
            sdpMLineIndex: event.candidate.sdpMLineIndex,
          },
        });
        this.sendMediaEvent(mediaEvent);
      }
    };
  };

  private onIceCandidateError = (event: RTCPeerConnectionIceErrorEvent) => {
    console.warn(event);
  };

  private onConnectionStateChange = (_event: Event) => {
    switch (this.connection?.connectionState) {
      case "connected":
        this.processNextCommand();
        break;
      case "failed":
        this.emit("connectionError", "Connection failed");
        break;
    }
  };

  private onIceConnectionStateChange = (_event: Event) => {
    const errorMessages = "Ice connection failed";

    switch (this.connection?.iceConnectionState) {
      case "disconnected":
        console.warn("ICE connection: disconnected");
        break;
      case "failed":
        this.emit("connectionError", errorMessages);
        break;
      case "connected":
        this.processNextCommand();
        break;
    }
  };

  private onIceGatheringStateChange = (_event: any) => {
    switch (this.connection?.iceGatheringState) {
      case "complete":
        this.processNextCommand();
        break;
    }
  };

  private onSignalingStateChange = (_event: any) => {
    switch (this.connection?.signalingState) {
      case "stable":
        this.processNextCommand();
        break;
    }
  };

  private onTrack = () => {
    return (event: RTCTrackEvent) => {
      const [stream] = event.streams;
      const mid = event.transceiver.mid!;

      const trackId = this.midToTrackId.get(mid)!;
      if (this.checkIfTrackBelongToEndpoint(trackId, this.localEndpoint)) return;

      const trackContext = this.trackIdToTrack.get(trackId)!;
      trackContext.stream = stream;
      trackContext.track = event.track;

      this.emit("trackReady", trackContext);
    };
  };

  private setTurns = (turnServers: any[]): void => {
    turnServers.forEach((turnServer: any) => {
      let transport, uri;
      if (turnServer.transport == "tls") {
        transport = "tcp";
        uri = "turns";
      } else {
        transport = turnServer.transport;
        uri = "turn";
      }

      const rtcIceServer: RTCIceServer = {
        credential: turnServer.password,
        urls: uri.concat(":", turnServer.serverAddr, ":", turnServer.serverPort, "?transport=", transport),
        username: turnServer.username,
      };

      this.rtcConfig.iceServers!.push(rtcIceServer);
    });
  };

  private addEndpoint = (endpoint: Endpoint): void => {
    // #TODO remove this line after fixing deserialization
    if (Object.prototype.hasOwnProperty.call(endpoint, "trackIdToMetadata"))
      endpoint.tracks = new Map(Object.entries(endpoint.tracks));
    else endpoint.tracks = new Map();

    this.idToEndpoint.set(endpoint.id, endpoint);
  };

  private eraseEndpoint = (endpoint: Endpoint): void => {
    const tracksId = Array.from(endpoint.tracks.keys());
    tracksId.forEach((trackId) => this.trackIdToTrack.delete(trackId));
    Array.from(this.midToTrackId.entries()).forEach(([mid, trackId]) => {
      if (tracksId.includes(trackId)) this.midToTrackId.delete(mid);
    });
    this.idToEndpoint.delete(endpoint.id);
  };

  private eraseTrack = (trackId: string, endpointId: string) => {
    this.trackIdToTrack.delete(trackId);
    const midToTrackId = Array.from(this.midToTrackId.entries());
    const [mid, _trackId] = midToTrackId.find(([_mid, mapTrackId]) => mapTrackId === trackId)!;
    this.midToTrackId.delete(mid);
    this.idToEndpoint.get(endpointId)!.tracks.delete(trackId);
    this.disabledTrackEncodings.delete(trackId);
  };

  private getEndpointId = () => this.localEndpoint.id;

  private mapMediaEventTracksToTrackContextImpl = (
    tracks: [string, any][],
    endpoint: Endpoint,
  ): Map<string, TrackContextImpl> => {
    const mappedTracks: Array<[string, TrackContextImpl]> = Array.from(tracks).map(([trackId, track]) => [
      trackId,
      new TrackContextImpl(endpoint, trackId, track.metadata, track.simulcastConfig),
    ]);

    return new Map(mappedTracks);
  };
}
